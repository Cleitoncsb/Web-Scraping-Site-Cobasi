h1>Web Scraping Site Cobasi</h1>


![Imagem1](https://github.com/Cleitoncsb/meu-Portfolio/assets/142935223/b9bf12f2-c1a3-46af-a8a8-b2fade673657)


 <h2> üìå Overview   </h2>
 
 Este projeto exemplifica o uso eficaz da automa√ß√£o e do web scraping na era digital para simplificar e 
 acelerar a coleta de dados de sites, uma tarefa normalmente demorada e propensa a erros. <br>
 Empregando scripts automatizados 
 para extrair dados de forma eficiente e precisa, ele oferece aplica√ß√µes pr√°ticas em diversos campos, desde an√°lise de mercado at√© pesquisa 
 acad√™mica, destacando-se pela efici√™ncia na redu√ß√£o de tempo e erros, al√©m de sua adaptabilidade para diferentes tipos de dados e sites.

<h2> ü™í Um pouco sobre Web Scraping</h2>

Web scraping √© uma t√©cnica de automa√ß√£o para extrair dados de websites, empregando scripts para coletar informa√ß√µes de forma r√°pida e estruturada.<br>
Por exemplo, pode ser usado por empresas de e-commerce para monitorar os pre√ßos dos concorrentes, ajustando suas pr√≥prias estrat√©gias de pre√ßos e marketing com base nesses dados. 

<h2> üìä Resultados e Insigths</h2>
O resultado do c√≥digo acima, retorna um excel com 80 linhas sendo 40 linhas referente a cada uma das URLs contidas no c√≥digo, sendo armazenadas 
os campos referente ao produto e ao pre√ßo.<br>
<br>

![Captura de Tela 2023-12-12 √†s 22 19 25](https://github.com/Cleitoncsb/Analise-de-Dados-de-uma-Cafeteria-com-Python/assets/142935223/cf4a7c5f-6d65-49a5-b907-faee89cc7470)
<br>

<h2>Sobre a Metodologia</h2>
A aplica√ßƒÅo utilizada no c√≥digo, segue os seguintes passos:<br>
1. Inicializa√ß√£o do WebDriver do Safari: O c√≥digo come√ßa inicializando o Selenium WebDriver para o navegador Safari. 
Este WebDriver age como um navegador automatizado que pode ser controlado pelo script. <br>
2. Acessar URLs e Coletar Dados: O c√≥digo ent√£o percorre uma lista de URLs espec√≠ficas (neste caso, p√°ginas de produtos de um site de e-commerce). 
Para cada URL, ele carrega a p√°gina e aguarda um tempo (5 segundos) para que todo o conte√∫do, incluindo elementos gerados por JavaScript, seja carregado.<br>
3. Extra√ß√£o de Dados com BeautifulSoup: Ap√≥s carregar a p√°gina, o c√≥digo usa o BeautifulSoup para analisar o HTML da p√°gina. Ele procura por cont√™ineres 
espec√≠ficos que cont√™m informa√ß√µes sobre produtos e pre√ßos, usando as classes CSS para identific√°-los.<br>
4. Armazenamento dos Dados: Para cada cont√™iner encontrado, o c√≥digo extrai o texto do nome do produto e do pre√ßo. Essas informa√ß√µes s√£o armazenadas em um 
dicion√°rio e adicionadas a uma lista chamada produtos.<br>
5. Salvar Dados em Excel: Ap√≥s coletar todos os dados necess√°rios, o script converte a lista de dicion√°rios em um DataFrame do Pandas e salva esses dados em um arquivo Excel.<br>
6. Encerramento do WebDriver: Por fim, o WebDriver √© fechado para liberar recursos.<br>
